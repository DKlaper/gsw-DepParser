\documentclass[11pt,letterpaper, covington]{article}
\usepackage{fullpage}
\usepackage[pdftex]{graphicx}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsfonts,eucal,amsbsy,amsopn,amsmath}
\usepackage{url}
\usepackage{covington}
\usepackage[sort&compress]{natbib}
\usepackage{natbibspacing}
\usepackage{latexsym}
\usepackage{wasysym} 
\usepackage{rotating}
\usepackage{fancyhdr}
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator*{\argmin}{argmin}
\usepackage{sectsty}
\usepackage[dvipsnames,usenames]{color}
\usepackage{multicol}
\definecolor{orange}{rgb}{1,0.5,0}
\usepackage{multirow}
\usepackage{sidecap}
\usepackage{caption}
\renewcommand{\captionfont}{\small}
\setlength{\oddsidemargin}{-0.04cm}
\setlength{\textwidth}{16.59cm}
\setlength{\topmargin}{-0.04cm}
\setlength{\headheight}{0in}
\setlength{\headsep}{0in}
\setlength{\textheight}{22.94cm}
\allsectionsfont{\normalsize}
\newcommand{\ignore}[1]{}
\newenvironment{enumeratesquish}{\begin{list}{\addtocounter{enumi}{1}\arabic{enumi}.}{\setlength{\itemsep}{-0.25em}\setlength{\leftmargin}{1em}\addtolength{\leftmargin}{\labelsep}}}{\end{list}}
\newenvironment{itemizesquish}{\begin{list}{\setcounter{enumi}{0}\labelitemi}{\setlength{\itemsep}{-0.25em}\setlength{\labelwidth}{0.5em}\setlength{\leftmargin}{\labelwidth}\addtolength{\leftmargin}{\labelsep}}}{\end{list}}

\bibpunct{(}{)}{;}{a}{,}{,}
\newcommand{\nascomment}[1]{\textcolor{blue}{\textbf{[#1 --NAS]}}}


\pagestyle{fancy}
\lhead{}
\chead{}
\rhead{}
\lfoot{}
\cfoot{\thepage~of \pageref{lastpage}}
\rfoot{}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}


\title{11-712:  NLP Lab Report}
\author{David Klaper}
\date{April 25, 2014 \nascomment{due date}}

\begin{document}
\maketitle
\begin{abstract}
\nascomment{one paragraph here summarizing what the paper is about}
\end{abstract}

\nascomment{brief introduction}

\section{Basic Information about Swiss German}

Swiss German is a group of Germanic dialects spoken in Switzerland. In 2000, about 4.6 million people in Switzerland spoke Swiss German \citep{LGC13}. By now, this number probably has increased since the overall population of Switzerland increased from 7.2 to 8 million people since 2000 \citep{BFS13}. In general, Swiss German is quite similar to Standard German there are specific syntactic, lexical and other differences between Standard German and the Swiss German dialects. There are also considerable differences with regard to these features between different dialects. \citep{Scherrer11}

\section{Past Work on the Syntax of Swiss German}

The name Swiss German already indicates that it is closely related to (Standard) German. Many words and the basic syntactic structure are similar or equal to German. One often-cited characteristic of Swiss German is the existence of context-sensitive structures in some dialects as shown by \cite{Shieber85}.

Due to the similarity to Standard German it makes sense to consider resources for Standard German syntax. There are many resources on Standard German syntax. One of them is the World Atlas of Language Structures \citep{DH13}. It summarizes the syntactic and morphologic properties of a language as a list of features. Furthermore, there exist dependency treebanks and dependency parsers for Standard German. As an example \citet{SSVW09} present a hybrid dependency parser, which combines hand-written rules with a statistical model. The parser relies on supervised training data, which is not available for Swiss German yet.

We have seen that for Standard German there exist many powerful tools and datasets. Unfortunately, there are still considerable differences between the two. First, Swiss German is mainly a spoken language and no unified writing system exists. Furthermore, even within Switzerland the dialects vary considerably regarding pronunciation and in consequence spelling. 

\citet{Scherrer07} attempted to normalize Swiss German words to their Standard German counterparts, which would allow using the Standard German resources. Although he created a working system, the results are below 50\% for both precision and recall. Scherrer states also that ``for many dialect words, it yields no result at all'' \citep[p. 60]{Scherrer07}. \citet{SR10} worked towards machine translation from Standard German to specific Swiss German dialects and outlined how to use Standard German resources for creating a Swiss German constituent parser. This work is very interesting but it requires dialect identification and the performance is not good enough. Specifically, introducing a high error rate in a preprocessing step will make building a robust dependency parser even harder. 

As stated before there are differences between Standard German and Swiss German as well as between the different Swiss German dialects. \citet{Scherrer11} proposes a system to normalize Swiss German dialects to Standard German syntax and explains some of the syntactic differences. \citet{BG02} started a project for mapping the differences between the Swiss German dialects in an atlas. However, as of the beginning of 2014 the atlas has not been published. As part of this project \citet{GF06} investigated reduplication phenomena in Swiss German dialects. 

Beyond the resources describing Swiss German syntax and some tools to standardize Swiss German there are very few tools available. Also, there are no freely available corpora published yet, but \citet{AH14} at the University of Zurich are working on a corpus of 50'000 tokens annotated with \emph{Part-of-Speech} (PoS) tags. They are also building a PoS-Tagger for Swiss German. They trained a model which got them approximately 85\% accuracy on Alemannic Wikipedia texts with 20'000 tokens training. \citep{AH12}. It does not discriminate between different dialects, which eliminates dialect identification as a source of error. Dialect identification is especially difficult because the borders are continuous and many people have lived in multiple dialect areas and have a mix of dialects (e.g. the writer of this document). This tagger could be very useful for the parser.

In conclusion, while Swiss German has many similarities with Standard German, for which many resources exist. The attempts to normalize Swiss German dialects to Standard German have yielded mediocre performance. There are some dialectometric studies detailing the differences between the distinct dialects but very few computational systems and no corpora. \citet{AH14} are working on a corpus and PoS-Tagger for Swiss German. This tagger will not discriminate between different dialects which eliminates the dialect identification.

\section{Available Resources}

Since Swiss German is a mainly spoken language, written resources are sparse. In particular, organized corpora are basically non-existant or transcribed resources from interviews or otherwise artificial written text. The Zürcher Kompetenzzentrum für Linguistik (Zurich compentency center for linguistics) compiled a ist of corpora\footnote{\url{http://www.linguistik.uzh.ch/resources/korpora.html} last checked January 31$^{st}$, 2014.}. The problem with the list is that there are non-working links and most resources are only available on request and may not be shared. Finally, as mentioned above most of these resources are geared towards linguistic analysis use and are just transcriptions of spoken language. 

For building their PoS tagger, \citet{AH12} compiled data from the Alemannic Wikipedia\footnote{\url{http://als.wikipedia.org} last checked last checked January 31$^{st}$, 2014.} and annotated 20'000 tokens with PoS tags. Since the seminar thesis they have significantly increased the scope and size of their corpus. By now they have annotated over 50'000 tokens. First, there is a Swiss German edition of the 2012 corporate report of the Swiss firm Swatch\footnote{Report available at \url{http://www.swatchgroup.com/de/investor_relations/jahres_und_halbjahresberichte} last checked January 31$^{st}$, 2014.}. The report contains more than 70'000 tokens of which 13'000 were annotated with PoS tags. Another source they used is the anniversary edition of a daily free newspaper in Switzerland \footnote{Edition May 28$^th$, 2013 in the archive at \url{http://www.blick.ch/blickamabend/epaper/}  last checked January 31$^{st}$, 2014.}, which was a special edition written in Swiss German. They annotated about 11'000 tokens. They also annotated extracts from murder stories by Viktor Schobinger\footnote{\url{http://www.zuerituetsch.ch/zueri-krimi.html}  last checked January 31$^{st}$, 2014.} but I decided not to use this part, because the domain is quite different and probably even more difficult than the rest. \citep{AH14}

In order to complement these resources, I decided to compile a new collection of Swiss German texts from the web, as an additional ressource. I was considering Twitter text but this will probably be too noisy. Also, it might be hard to detect whether a short tweet is Swiss German or not. Therefore, I decided to search for Swiss German blogs. I restricted myself to blogspot blogs, in order to facilitate subsequent extraction. Using google queries involving typical Swiss German words and `blog' I searched for mainly Swiss German blogs. Using this technique, I selected 17 blogs from people posting entries written in Swiss German. Interestingly, the queries I used returned almost exclusively returned blogs from Swiss people doing an exchange program or living abroad. I extracted 885 blog entries (but some contain only pictures no text and a few are in languages other than Swiss German). 

I then proceeded to filter out useless posts. I extracted the xml, removed html tags and wrote each blog entry into its own file with the pattern `blog\_\emph{blognumber}\_\emph{postnumber}.txt'. The blog number relates to one of the original 17 blogs. The postnumber indicates how old an entry is. Hence, the postnumber is in inverse chronological order. After extracting the text from the xml, I removed all files that were empty or less than 100 Bytes, since many posts only included pictures. The, I manually went through all blog posts, deleting the entries with more than half written in another language. In a few special cases, e.g. song lyrics, I just removed these and kept the blog post if they were not vital to the content. At the end 615 blog posts remained.

After cleaning the data I wrote a script to count the tokens. As a token I defined a sequence of alphabetical or numerical characters of length 2 or more. Note that this definition ignores punctuation. I will later use a tokenization script provided by \citet{AH14}, where the count will be higher, but for now this is precise enough. The token count was 277'000 with 32'402 types. This is a type-to-token ratio of 11.7\%, which is fairly high. Moreover, over half of the types (19'397) occur only once, i.e., they are hapax legonoma.

Also, I will forward the data to \citet{AH14} and they will annotate part of it to make it part of their tagger training material. A side resource I might use (depending on the parsing framework I use) is a list of Swiss German words without German roots\footnote{\url{http://www.dialektwoerter.ch} last checked January 31$^{st}$, 2014.}. If this word list helps, I might also consider German word lists.

\begin{table}
\center
\begin{tabular}{ | l | c | c | }
   \hline
   \textbf{Source} & \textbf{Tokens with PoS} & \textbf{Tokens overall} \\ \hline
   Wikipedia & 20'000 & 60'000 \\
   Newspaper & 11'000 & 17'000 \\ 
   Swatch Report & 13'000 & 70'000 \\
   Blog Text & 0 & 277'000 \\ \hline
   \textbf{Total} & \textbf{44'000} & \textbf{424'000} \\ \hline
\end{tabular}
\caption{Rough estimated token counts}
\end{table}

For the reference corpora A and B, I plan to select data from each data set. In particular, corpus A will consist of a text-section from the Swatch report, Wikipedia, or the newspaper, which is at least 1000 tokens in one piece. Corpus B will consist of one or multiple blog posts from the same author, since the posts are usually reasonably contiguous. In short, I plan to use over 150'000 tokens Swiss German text from \cite{AH14} of which about 50'000 tokens are annotated with PoS-texts. In addition, I will use Swiss German blog text from mainly exchange students. This collection will have over 250'000 tokens Swiss German text, of which I can use most for training. This is most likely the largest collection of Swiss German written text in existence with over 400'000 tokens. I hope that such data will reduce the effect of the many different ways to write the same word in Swiss German.

\section{Survey of Phenomena in Swiss German}

The basic word order is a bit tricky in German since the main clause has a subject-verb-object (SVO) order but the subordinate clauses are verb-final, i.e., subject-object-verb (SOV). German has a richer morphology than English but in Swiss German some of the distinct cases collapse to the same wordform. Furthermore, Swiss German lacks a preterite tense, all sentences in the past are expressed using perfect. Finally, Swiss German does not have the genitive case. It is replaced by dative constructions. \citep{Scherrer11}

These are some general observations but the focus here is on syntactic phenomena that influence the dependency structure in crucial ways. \citet{Scherrer11} lists more interesting differences. One point are the non-projective dependencies in Swiss German. One reason for them is the verb raising with the auiliary verb ``lo'' (\emph{let}), where the dependency between the auxiliary and its argument and the main verb and its object will cross. There exist other forms of verb raising, where verb order differs from the Standard German word order. Also, this may depend on the dialect. In short, the word order of Swiss German is more free than Standard German. 

Some more phenomena that illustrate differences between the well-studied Standard German and Swiss German, are a preposition before a dative in the case it is not already part of a prepositional phrase. This would have more impact on constituent parsing though. \citet{Scherrer11} lists more phenomena but some of them seem rather uncommon in central Switzerland. In particular, the very southern dialects have even more deviations, but most of the population lives in central and northern Switzerland, therefore these effects might not occur very much in the corpora. A last part that might be particularly tricking for dependency annotation are doubling phenomena in Swiss German as explained by \citet{GF06}. For many of these phenomena it is not clear, which word is the head and which the dependent even if they are clearly related.

By inspection of the data, I looked for other interesting phenomena. One phenomena is the melting of verbs and personal pronouns (and similar combinations) that is also reflected in the tagset by \citet{AH12}. This is a major challenge for the annotation of dependencies, because the two words have independent syntactic roles but both its dependents will be added to this single token. There are many spelling variations, even within a document a term may not be written the same way or spaced differently in some cases. Hence, for data-oriented methods this may pose a problem. 

For the blog corpus, there are some specific observations. First, often vowels are duplicated multiple times to place emphasis on a word, such as ``gaaanz elei'' (\emph{totally alone}), which increases the number of types for the same lemma. Also, because the blogs are by Swiss people abroad there are many insertions of foreign language material, e.g. ``sWetter isch totally crazy gsi'' (\emph{the weather was totally crazy}).

In conclusion, Swiss German is generally more free regarding word order than Standard German, especially with regard to auxiliary and main verb. This may yield non-projective dependency relations. Furthermore, verb and personal pronouns can sometimes be contracted to one word, as other combinations can. The spelling is not uniform and duplication of vowels is common. For dependency annotation especially the frequent use of auxiliaries and the duplication of words can be difficult, since the head-dependent relation is not obvious in these cases.


\section{Initial Design}

This section describes the annotation design and briefly outlines the next steps, i.e., building the actual parser. As stated before my two test corpora have a different focus. Corpus A consists of a small part of the data by \citet{AH12}. Corpus B consists entirely of blog posts. The data was annotated manually. To ensure annotation consistency the following documents the annotation decisions made.

Table \ref{tab:dec} gives an overview of the annotation decisions. Before going into the detailed decisions an overall observation. The sentence splitting of my tokenizer is far from perfect, since capitalization can not be used as a feature of sentence splitting. First, because some people write all lower case and second, because in German common nouns are capitalized. Therefore, it is possible to have multiple words attached to the root, which mean that the clauses are independent. Most of the decisions are semantically oriented. Also, I sometimes give English-only examples, when the matter is the same in both languages.

Since Swiss German does not use a past form, many sentences have auxiliaries. \textbf{Decisions 1 and 2} say that in sentences with multipe verbal parts, the inflected auxiliary is always the head. This is illustrated in the example below. The subscript numbers indicate the position of the parent in the senence. Zero means root. The inflected verb \emph{het} dominates \emph{welle}, which dominates the main verb \emph{lösche}. \textbf{Decisions 3 and 4} concern the attachment of the arguments. The subject always attaches to the inflected verb as a child. Thus, \emph{hans} is a child of \emph{het}, all other arguments and adjuncts attach to the main verb, e.g. \emph{lösche}. There are certain special cases. Especially, modal verbs, such as \emph{cha} (`can') can be modified by adverbial constructs. These attach to the verb they modify. Sometimes this is hard to decide, then they are attached to the main verb.  Note that the verb \emph{sött} (`should') can be used as a main verb. The reason for this is that the importance of the first auxiliary is reflected and the connection between subject and form of the inflected verb is explicit. Furthermore, the main verb defines what kind of objects are allowed, therefore  it dominates the arguments.

\glll  1 2 3 4 5 6 7 8 9 10
De hans$_3$ het$_0$ welle$_3$ d' date$_{10}$ mit em magnet$_{10}$ lösche$_4$
The Hans has want the data with the magnet delete
\glt `Hans wanted to delete the data with the magnet'
\glend

\textbf{Decision 5} states that subordinate clauses are headed by the subjunction that introduces them. Hence, the head verb in the embedded clause is dependent on the relative pronoun (or other subjunctive word). The reasoning is that the subjunction defines how the clause relates to the main sentence and hence, acts as the root of the embedded clause.
\textbf{Decision 6} states that in a coordination the conjunction, typically \emph{ond} or \emph{und} (`and'), is the head of the conjuncts. Furthermore, should there be multiple parts to a conjunction of which all but the last are connected by commas, all parts of the conjunction will be direct dependents of and. (The comma is not reflected, since it is attached to the root, see below). If there are multiple `and' (that are not semantically in a hierarchy), the `and' dominate from left to right, i.e., the first and will be the highest.
\textbf{Decision 7} determines that in numerical expressions like \emph{öppe 3 stund} (`about 3 hours'), the unit is the head of the number and the number is the head of the modifier. The reason for this is that the number quantifies the unit and themodifier modifies the quantity.
\textbf{Decision 8} is related to the fact that certain verbs are built by prepending a particle in front of the verb. In infinitive constructions this particle can be split from the verb. It is clear that this particle is a direct dependent of the verb it belongs to.

The important \textbf{Decision 9} says that prepositional phrases are headed by the noun. The reason is that there are large variations in the use of prepositions among the dialects, while the noun is always there. Furthermore, some dialects use sequences of prepositions and articles, while others contract both to one word. \textbf{Decision10} states that discourse markers, such as interjections and smileys are attached to the corresponding head of the phrase they belong to. Note that smileys might be attached to the root if they are outside of a sentence  or clause context. Also, Swiss people use `and' and other conjunctions sometimes as discourse fillers or simple linking elements, in that case this rule applies and not the coordination rule.

A special phenomena is the contraction of different words in Swiss German. For instance, one can contract a relative pronoun \emph{wo} (`where, when') and the following personal pronoun \emph{ich} (`I') to \emph{wonich}. This  was also observed by \cite{AH12}. Therefore, they introduced multiple PoS tags to deal with such phenomena. The problem is where in the dependency parse these constructions with multiple roles should end up. \textbf{Decision11} is the word should always adopt its strongest role, i.e., the word part that is higher in the dependency parse will determine the position of the contracted word.
\textbf{Decision 12} concerns comparison phrases of the form below.
\glll  1 2 3 4 5 6
So schön$_0$ wie$_2$ de himmel$_6$ esch$_3$
So beautiful how the sky is
\glt `As beautiful as the sky (is)'
\glend
The point is that the main content of the phrase is the beauty. The verbal phrase is what is being compared to. It is a semantic construction to introduce a contrast. It cannot be inverted, thus, I decided that the verb is not the head in this case.  
\textbf{Decision 13} is similar to number 8. In German, `no more' can be split and the object that is not available anymore will be between the two parts. Here, the more is clearly a dependent of no.
\textbf{Decision 14} concerns sequences of multiple nouns. While general compounds are written together, some compounds can be split. There the head is the main content. However there is another special case. It is 'the word -bus-'. Here word will be the head and bus will be dependent. This is also a semantic decision, because the phrase is about a word not a bus.
\textbf{Decision 15} is also such a `meta'-concern. In the phrase "for example [X]", X will be the head and example will be dependent, because the semantic content is X.  

\textbf{Decision 16} states that in a sentence that has no verb, the next most important word becomes the head. There are even sentences where a noun is the head and then a finite relative clause is embedded. This inheritance principle makes sense, although in the case of ellipsis it might be hard to determine what exactly should be the head. The decision should also be semantically motivated.
\textbf{Decision 17} is simply all punctuation is strictly attached to the root. This is because punctuation is very unreliable in Swiss German, because the use by different speakers is inconsistent.

% Decisions have to be taken
 \begin{table}
\center
\begin{tabular}{ | l | l | r | }
   \hline
   \textbf{ID} & \textbf{Pattern} & \textbf{Head} \\ \hline
   1 & Mainverb Aux & Aux \\
   2 & Aux [...] Mainverb & Aux  \\ 
   3 & Subj & Inflected Verb  \\
   4 & Object, other Args, Adjuncts & Mainverb \\
   5 & RelPron Verb & RelPron \\
   6 & [XP] \emph{and} [XP] & \emph{and} \\
   7 & Mod Num Unit & Unit  \\
   8 & Mainverb VerbPart & Mainverb \\
   9 & Prep N &  N \\
   10 & DiscourseMarker & Corresponding Clause Head \\
   11 & Contractions & Placed At Highest \\
   12 & Adj Comparison MainVerb Aux & Comp \\
   13 & 2 Part Negation (\emph{no more}) & \emph{no}  \\
   14 & N\_descriptor N\_term & N\_descriptor \\
   15 & Example & Main content \\
   16 & No Verb Sentence & Next Best, e.g. Noun \\
   17 & Punctuation & ROOT\\ \hline
\end{tabular}
\caption{Annotation Decisions}
\label{tab:dec}
\end{table}

Finally. a couple of decisons not listed in the table, because they are minor. Foreign material, e.g. English, is annotated as much as possible according to English standards, where they exist or otherwise according to this manual. A sensitivity regarding passive formulations. In the passive voice, the main verb is a participle that may be hard to distinguish from an adjective, but it is as treated as a verb as long as it is clearly related to a verb. This leads to a distinction between `has been possible', where `been' will be the main verb that gets the arguments as its dependents and `has been registered', where 	`registered' is the main verb. There are subjunctions, such as \emph{aber} (`but'), which can also be used instead to just modify a verb phrase, then they are dependent of the verb. Last, in `dangerous to deadly', `dangerous' is the head of `to', which in turn is head of `deadly'. 

While in general the annotation worked quite well, it turns out that using and as the head of its conjuncts leads to unintuitive phenomena. In particular, if there is a coordinated verb phrase that applies to the same subject, then `and' dominates both the conjuncts and the subject, which clearly do not have the same function. However, I decided to stick to the annotation schema because I did want to avoid preferring one of the two conjunct phrases over the other. Arguably, `and' is also used as a linking word instead of a coordination, but this is a different case and should in my opinion not be mixed with the real coordination of phrases. 

The parser will operate in a semi-supervised fashion, making use of annotated training material as much as possible. It is important to use unsupervised features as well, because a large amount of the available texts will not be annotated. It would be bad not to use this data. The semi-supervised method by \citet{KCC08} based on Brown Clustering serves as the model for my unsupervised features.  I consider using the TurboParser \citep{MSXAF10} as a baseline. Then I would try adding unsupervised features to improve over the supervised baseline.

In conclusion, I tried to adopt a rather semantic notion of head and used this throughout the annotation. I will build a semi-supervised parser.

\section{System Analysis on Corpus A}

\section{Lessons Learned and Revised Design}

\section{System Analysis on Corpus B}

\section{Final Revisions}

\section{Future Work}


\section{Acknowledgements}
I'd like to thank Noëmi Aepli and Nora Hollenstein for supporting me with information about Research in Swiss German and especiallz for giving me early access to the Swiss German resources that they are developing. 

\bibliographystyle{plainnat}
\bibliography{refs}
\label{lastpage}
\end{document}
